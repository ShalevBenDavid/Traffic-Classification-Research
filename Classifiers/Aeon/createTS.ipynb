{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = \"../../Datasets/QUIC\"\n",
    "# all_sessions = []\n",
    "# labels = []\n",
    "# ## Iterating through all the folders and files in the given path.\n",
    "# ## Each folder represents a label.\n",
    "# ## Each file represents a session.\n",
    "# ## Each session is converted to a Pandas DataFrame.\n",
    "# for label in os.listdir(folder_path):\n",
    "#     label_folder_path = os.path.join(folder_path, label)\n",
    "#     if os.path.isdir(label_folder_path):\n",
    "#         for filename in os.listdir(label_folder_path):\n",
    "#             file_path = os.path.join(label_folder_path, filename)\n",
    "#             # Converting each session to Panda's DataFrame and restricting the number of rows. \n",
    "#             session_df = pd.read_csv(file_path, sep=\"\\t\", header=None, skiprows=4, nrows=150)\n",
    "#             # Giving names to the columns (features).\n",
    "#             session_df.columns = ['Timestamp', 'Time Difference', 'Packet Size', 'Direction']\n",
    "#             # Adding to the collection.\n",
    "#             if not session_df.empty:\n",
    "#                 all_sessions.append(session_df)\n",
    "#                 labels.append(label)\n",
    "# # Merge all DataFrames to one DataFrame.\n",
    "# all_data = pd.concat(all_sessions, ignore_index=True)\n",
    "\n",
    "# print(session_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #2d array of traffic\n",
    "# trafficArr = []\n",
    "# for session in all_sessions:\n",
    "#     # if direction is 1, multiply packet size by -1\n",
    "#     session.loc[session['Direction'] == 1, 'Packet Size'] *= -1\n",
    "#     # remove Timestamp and Direction columns\n",
    "#     session.drop(['Timestamp', 'Direction'], axis=1, inplace=True)\n",
    "#     traffic = []\n",
    "#     # create list of values between 0 and 5 with step 0.1\n",
    "#     values = np.arange(0, 5, 0.1)\n",
    "#     for timing in values:\n",
    "#         sum = 0\n",
    "#         for index, row in session.iterrows():   \n",
    "#             if row['Time Difference'] < timing+0.5 and row['Time Difference'] > timing:\n",
    "#                 sum += row['Packet Size']\n",
    "#             # else:\n",
    "#             #     break\n",
    "#         traffic.append(sum)\n",
    "#     # convert traffic to numpy array\n",
    "#     traffic = np.array(traffic)\n",
    "#     # add traffic to trafficArr\n",
    "#     trafficArr.append(traffic)\n",
    "# type(trafficArr)\n",
    "# # convert trafficArr to 2d-numpy array\n",
    "# trafficArr = np.array(trafficArr)\n",
    "\n",
    "# # save trafficArr to csv file\n",
    "# np.savetxt(\"traffic.csv\", trafficArr, delimiter=\",\")\n",
    "# # save labels to csv file\n",
    "# np.savetxt(\"labels.csv\", labels, delimiter=\",\", fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficArr = np.loadtxt(open(\"traffic.csv\", \"rb\"), delimiter=\",\")\n",
    "labels = np.loadtxt(open(\"labels.csv\", \"rb\"), delimiter=\",\", dtype=str)\n",
    "\n",
    "# convert labels to numpy array\n",
    "labels = np.array(labels)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(trafficArr, labels, test_size=0.2, random_state=42,stratify=labels)\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9557453416149069\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Google Doc       1.00      0.96      0.98       244\n",
      " Google Drive       0.95      0.95      0.95       327\n",
      " Google Music       0.92      0.90      0.91       118\n",
      "Google Search       0.99      0.99      0.99       383\n",
      "      Youtube       0.89      0.93      0.91       216\n",
      "\n",
      "     accuracy                           0.96      1288\n",
      "    macro avg       0.95      0.95      0.95      1288\n",
      " weighted avg       0.96      0.96      0.96      1288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rand_forest = RandomForestClassifier(n_estimators=100)\n",
    "rand_forest.fit(X_train, y_train)\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9091614906832298\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Google Doc       1.00      0.98      0.99       244\n",
      " Google Drive       0.97      0.88      0.92       327\n",
      " Google Music       0.77      0.72      0.75       118\n",
      "Google Search       0.98      0.97      0.97       383\n",
      "      Youtube       0.72      0.88      0.79       216\n",
      "\n",
      "     accuracy                           0.91      1288\n",
      "    macro avg       0.89      0.88      0.88      1288\n",
      " weighted avg       0.92      0.91      0.91      1288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from aeon.classification.convolution_based import RocketClassifier\n",
    "\n",
    "rocket = RocketClassifier(num_kernels=2000)\n",
    "rocket.fit(X_train, y_train)\n",
    "y_pred = rocket.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9386645962732919\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Google Doc       0.97      0.98      0.97       244\n",
      " Google Drive       0.96      0.94      0.95       327\n",
      " Google Music       0.84      0.82      0.83       118\n",
      "Google Search       0.98      0.97      0.98       383\n",
      "      Youtube       0.85      0.89      0.87       216\n",
      "\n",
      "     accuracy                           0.94      1288\n",
      "    macro avg       0.92      0.92      0.92      1288\n",
      " weighted avg       0.94      0.94      0.94      1288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from aeon.classification.hybrid import HIVECOTEV2\n",
    "\n",
    "hc2 = HIVECOTEV2(time_limit_in_minutes=0.2)\n",
    "hc2.fit(X_train, y_train)\n",
    "y_pred = hc2.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCMeta\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "tensorflow and tensorflow-probability are required for deep learning and probabilistic functionality in `aeon`. To install these dependencies, run: `pip install aeon[dl]`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/aeon-env/lib/python3.11/site-packages/aeon/utils/validation/_dependencies.py:220\u001b[0m, in \u001b[0;36m_check_dl_dependencies\u001b[0;34m(msg, severity)\u001b[0m\n\u001b[1;32m    219\u001b[0m import_module(\u001b[39m\"\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 220\u001b[0m import_module(\u001b[39m\"\u001b[39;49m\u001b[39mtensorflow_probability\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    221\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/aeon-env/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_probability'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/chenhajaj/Library/CloudStorage/GoogleDrive-chenha@g.ariel.ac.il/My Drive/Papers & Code/Traffic-Classification-Research/Classifiers/Aeon/createTS.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenhajaj/Library/CloudStorage/GoogleDrive-chenha%40g.ariel.ac.il/My%20Drive/Papers%20%26%20Code/Traffic-Classification-Research/Classifiers/Aeon/createTS.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenhajaj/Library/CloudStorage/GoogleDrive-chenha%40g.ariel.ac.il/My%20Drive/Papers%20%26%20Code/Traffic-Classification-Research/Classifiers/Aeon/createTS.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chenhajaj/Library/CloudStorage/GoogleDrive-chenha%40g.ariel.ac.il/My%20Drive/Papers%20%26%20Code/Traffic-Classification-Research/Classifiers/Aeon/createTS.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     model \u001b[39m=\u001b[39m CNNClassifier()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenhajaj/Library/CloudStorage/GoogleDrive-chenha%40g.ariel.ac.il/My%20Drive/Papers%20%26%20Code/Traffic-Classification-Research/Classifiers/Aeon/createTS.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenhajaj/Library/CloudStorage/GoogleDrive-chenha%40g.ariel.ac.il/My%20Drive/Papers%20%26%20Code/Traffic-Classification-Research/Classifiers/Aeon/createTS.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/aeon-env/lib/python3.11/site-packages/aeon/classification/deep_learning/cnn.py:133\u001b[0m, in \u001b[0;36mCNNClassifier.__init__\u001b[0;34m(self, n_layers, kernel_size, n_filters, avg_pool_size, activation, padding, strides, dilation_rate, n_epochs, batch_size, callbacks, file_path, save_best_model, save_last_model, best_file_name, last_file_name, verbose, loss, metrics, random_state, use_bias, optimizer)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    109\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    110\u001b[0m     n_layers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m     optimizer\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    132\u001b[0m ):\n\u001b[0;32m--> 133\u001b[0m     _check_dl_dependencies(severity\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39merror\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    134\u001b[0m     \u001b[39msuper\u001b[39m(CNNClassifier, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(last_file_name\u001b[39m=\u001b[39mlast_file_name)\n\u001b[1;32m    136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_layers \u001b[39m=\u001b[39m n_layers\n",
      "File \u001b[0;32m~/miniconda3/envs/aeon-env/lib/python3.11/site-packages/aeon/utils/validation/_dependencies.py:224\u001b[0m, in \u001b[0;36m_check_dl_dependencies\u001b[0;34m(msg, severity)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    223\u001b[0m     \u001b[39mif\u001b[39;00m severity \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 224\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[39melif\u001b[39;00m severity \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwarning\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    226\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(msg, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: tensorflow and tensorflow-probability are required for deep learning and probabilistic functionality in `aeon`. To install these dependencies, run: `pip install aeon[dl]`"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#from aeon.classification.deep_learning import CNNClassifier, FCNClassifier, EncoderClassifier, IndividualInceptionClassifier, MLPClassifier, ResNetClassifier, ShallowConvNetClassifier, TLENETClassifier, ResNetClassifier, TapNetClassifier\n",
    "from aeon.classification.deep_learning.base import BaseDeepClassifier\n",
    "from aeon.classification.deep_learning.cnn import CNNClassifier\n",
    "from aeon.classification.deep_learning.encoder import EncoderClassifier\n",
    "from aeon.classification.deep_learning.fcn import FCNClassifier\n",
    "from aeon.classification.deep_learning.inception_time import (\n",
    "    InceptionTimeClassifier,\n",
    "    IndividualInceptionClassifier,\n",
    ")\n",
    "from aeon.classification.deep_learning.mlp import MLPClassifier\n",
    "from aeon.classification.deep_learning.resnet import ResNetClassifier\n",
    "from aeon.classification.deep_learning.tapnet import TapNetClassifier\n",
    "\n",
    "models = [BaseDeepClassifier, CNNClassifier, EncoderClassifier, FCNClassifier, InceptionTimeClassifier, IndividualInceptionClassifier, MLPClassifier, ResNetClassifier, TapNetClassifier]\n",
    "\n",
    "for model in models:\n",
    "    print(model.__class__.__name__)\n",
    "    model = CNNClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
